# Investigaci√≥n e Implementaci√≥n de una GigaGAN

<p align="center">
  <img src="https://github.com/warc0s/GigaGAN_Research/blob/main/logo_gigaGAN.png?raw=true" alt="GigaGAN Research" width="95%">
</p>

## Descripci√≥n General
Este repositorio presenta una exploraci√≥n exhaustiva que abarca tanto la investigaci√≥n te√≥rica como una implementaci√≥n pr√°ctica completa de una **GigaGAN**. El proyecto culmina con una GigaGAN para la generaci√≥n de im√°genes de Pastores Alemanes, utilizando un dataset sint√©tico generado localmente. Puedes consultar el detalle te√≥rico sobre GigaGAN en [investigacion.md](investigacion.md) y la implementaci√≥n pr√°ctica en el [cuaderno Jupyter](GigaGAN_GS.ipynb).

## üìÅ Estructura del Repositorio
- `investigacion.md` - Investigaci√≥n t√©cnica detallada sobre GigaGAN
- `GigaGAN_GS.ipynb` - Cuaderno Jupyter con la implementaci√≥n completa, proceso de entrenamiento y resultados 
- `checkpoints/` - Checkpoints del modelo guardados cada 5 √©pocas (hasta la √©poca 100)
- `epoch_images/` - Visualizaci√≥n del progreso de entrenamiento (muestras 3x3) guardadas cada 5 √©pocas

## üîç Detalles de la Implementaci√≥n Pr√°ctica
 
### Generaci√≥n del Dataset
- **Origen**: Dataset sint√©tico generado localmente mediante **Flux Schnell** (una versi√≥n destilada y m√°s eficiente de Flux Dev)
- **Especificaciones**:
  - 5,000 im√°genes en resoluci√≥n 256x256
  - Escenarios diversos y realistas (parques, entornos urbanos, fondos nevados, etc.)
  - Tiempo de generaci√≥n: ~2 horas en mi RTX 3090
- **Disponibilidad del dataset**: Tras completar la generaci√≥n del dataset, decid√≠ compartirlo con la comunidad subi√©ndolo a Kaggle para que otros investigadores y entusiastas puedan beneficiarse de √©l. Est√° disponible en [este enlace](https://www.kaggle.com/datasets/warc0s/german-shepherd)

### Proceso del Entrenamiento
- **Preprocesamiento**: Redimensionado a 128x128 para acelerar el entrenamiento
- **Duraci√≥n del entrenamiento**: 100 √©pocas (~18 horas en mi RTX 3090)
- **Monitorizaci√≥n**:
  - Checkpoints sistem√°ticamente guardados cada 5 √©pocas (archivos `.pth`)
  - Visualizaci√≥n detallada del progreso mediante muestras 3x3

### Evoluci√≥n del Entrenamiento
![Training GIF](https://github.com/warc0s/GigaGAN_Research/blob/main/epoch_images/output.gif?raw=true)

## üìù Investigaci√≥n Te√≥rica
Para terminar, recuerdo que el archivo [investigacion.md](investigacion.md) contiene un an√°lisis en profundidad de la arquitectura GigaGAN, incluyendo sus autores, tecnolog√≠as clave, innovaciones principales y comparativas con otras GANs similares as√≠ como modelos de difusi√≥n.

## üìï Recursos y Lecturas Complementarias

Este repositorio, e investigaci√≥n, se ha basado en los siguientes recursos:

- [MarkTechPost ‚Äì Meet GigaGAN: A Large-Scale Modified GAN Architecture for Text-to-Image Synthesis](https://www.marktechpost.com/2023/03/13/meet-gigagan-a-large-scale-modified-gan-architecture-for-text-to-image-synthesis/)
- [Sitio Oficial de Minguk Kang ‚Äì GigaGAN](https://mingukkang.github.io/GigaGAN/)
- [Auxo Digital ‚Äì The Dawn of GigaGAN: A New Contender in the AI Image Generation Arena](https://auxo.digital/blogs/the-dawn-of-gigagan-a-new-contender-in-the-ai-image-generation-arena)
- [Spring24 ‚Äì Advanced GAN Lecture (PDF)](https://slazebni.cs.illinois.edu/spring24/lec12_gan_advanced.pdf)
- [GitHub ‚Äì gigagan-pytorch by lucidrains](https://github.com/lucidrains/gigagan-pytorch)
- [YouTube ‚Äì Video sobre GigaGAN](https://www.youtube.com/watch?v=ZjxtuDQkOPY)
- [GitHub ‚Äì Minguk Kang‚Äôs GigaGAN](https://github.com/mingukkang/GigaGAN/)

## üìÑ Licencia
Este proyecto est√° bajo la Licencia MIT.
